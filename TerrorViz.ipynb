{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Project-Hackathons/LifeHack2024/blob/main/TerrorViz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZp_U3s-L1ra"
      },
      "source": [
        "# Automated Knowledge Graph Creation and Querying for Terrorism Reports Using LLMs\n",
        "## **Introduction**\n",
        "\n",
        "In the context of terrorism, reports and articles often contain extensive, unstructured text that is challenging to analyze and cross-reference in an automated manner. For instance, articles about a single terror incident might arrive at different times throughout the day, each with varying details. These reports typically include crucial entities such as *persons, objects, locations, and events*.\n",
        "\n",
        "<br>\n",
        "\n",
        "The objective of this project is to design and implement a solution using Large Language Models (LLMs) to:\n",
        "\n",
        "1. Extract entities from these reports and represent them in a structured knowledge graph.\n",
        "2. Develop a chatbot capable of answering questions based on the generated knowledge graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP-YZNpqVHXj"
      },
      "source": [
        "# Our Solution\n",
        "blablabal (ADD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPkDyBARM8yr"
      },
      "source": [
        "# Dependencies\n",
        "To run this project, the following dependencies are required:\n",
        "\n",
        "*   langchain: A library to facilitate the creation of language models\n",
        "*   neo4j: A graph database management system to store and query the knowledge graph.\n",
        "*  openai: To access and use OpenAI's language models.\n",
        "*   wikipedia: To extract data from Wikipedia for enriching the knowledge graph.\n",
        "*   tiktoken: For tokenization tasks required by the language models.\n",
        "*   langchain_openai: Integrates LangChain with OpenAI's models.\n",
        "*   langchain-community: Additional LangChain community tools and integrations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aHbRmW4KhiJb",
        "outputId": "1abc86b5-9bd7-47ea-af95-0c801f291d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in ./.venv/lib/python3.9/site-packages (0.2.1)\n",
            "Requirement already satisfied: neo4j in ./.venv/lib/python3.9/site-packages (5.20.0)\n",
            "Requirement already satisfied: openai in ./.venv/lib/python3.9/site-packages (1.30.5)\n",
            "Requirement already satisfied: wikipedia in ./.venv/lib/python3.9/site-packages (1.4.0)\n",
            "Requirement already satisfied: tiktoken in ./.venv/lib/python3.9/site-packages (0.7.0)\n",
            "Requirement already satisfied: langchain_openai in ./.venv/lib/python3.9/site-packages (0.1.8)\n",
            "Requirement already satisfied: langchain-community in ./.venv/lib/python3.9/site-packages (0.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.9/site-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.9/site-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.venv/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in ./.venv/lib/python3.9/site-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.9/site-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.9/site-packages (from langchain) (0.1.65)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.9/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.9/site-packages (from langchain) (2.7.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.9/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: pytz in ./.venv/lib/python3.9/site-packages (from neo4j) (2024.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.9/site-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.9/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.9/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.9/site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.9/site-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.9/site-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.9/site-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.9/site-packages (from langchain-community) (0.6.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.3 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.9/site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain neo4j openai wikipedia tiktoken langchain_openai langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeY1BRfIptQm"
      },
      "source": [
        "> This following section retrieves secret credentials for the project. The Neo4jGraph class from the langchain library is then used to create a Neo4jGraph instance with the retrieved credentials, enabling interaction with the Neo4j database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jwUzgb28mdw8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kenf/Developer/lifehack/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#import secrets and initialise Neo4jGraph\n",
        "from langchain.graphs import Neo4jGraph\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "graph = Neo4jGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maqbU8MdVEAm"
      },
      "source": [
        "> Here, we have modified the properties to be a list of Property instances instead of a dictionary to address the API's limitations. Since the API allows passing only a single object, we combine the nodes and relationships into a single class called KnowledgeGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aCQQjZnftvgB"
      },
      "outputs": [],
      "source": [
        "#overwrite some of the properties definition\n",
        "#this is to adhere to limitations of OpenAi functions\n",
        "from langchain_community.graphs.graph_document import (\n",
        "    Node as BaseNode,\n",
        "    Relationship as BaseRelationship,\n",
        "    GraphDocument,\n",
        ")\n",
        "from langchain.schema import Document\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain.pydantic_v1 import Field, BaseModel\n",
        "\n",
        "class Property(BaseModel):\n",
        "  \"\"\"A single property consisting of key and value\"\"\"\n",
        "  key: str = Field(..., description=\"key\")\n",
        "  value: str = Field(..., description=\"value\")\n",
        "\n",
        "class Node(BaseNode):\n",
        "    properties: Optional[List[Property]] = Field(\n",
        "        None, description=\"List of node properties\")\n",
        "\n",
        "class Relationship(BaseRelationship):\n",
        "    properties: Optional[List[Property]] = Field(\n",
        "        None, description=\"List of relationship properties\"\n",
        "    )\n",
        "\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
        "    nodes: List[Node] = Field(\n",
        "        ..., description=\"List of nodes in the knowledge graph\")\n",
        "    rels: List[Relationship] = Field(\n",
        "        ..., description=\"List of relationships in the knowledge graph\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "63OZD7fkukHM"
      },
      "outputs": [],
      "source": [
        "def format_property_key(s: str) -> str:\n",
        "    words = s.split()\n",
        "    if not words:\n",
        "        return s\n",
        "    first_word = words[0].lower()\n",
        "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
        "    return \"\".join([first_word] + capitalized_words)\n",
        "\n",
        "def props_to_dict(props) -> dict:\n",
        "    \"\"\"Convert properties to a dictionary.\"\"\"\n",
        "    properties = {}\n",
        "    if not props:\n",
        "      return properties\n",
        "    for p in props:\n",
        "        properties[format_property_key(p.key)] = p.value\n",
        "    return properties\n",
        "\n",
        "def map_to_base_node(node: Node) -> BaseNode:\n",
        "    \"\"\"Map the KnowledgeGraph Node to the base Node.\"\"\"\n",
        "    properties = props_to_dict(node.properties) if node.properties else {}\n",
        "    # Add name property for better Cypher statement generation\n",
        "    properties[\"name\"] = node.id.title()\n",
        "    return BaseNode(\n",
        "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
        "    )\n",
        "\n",
        "\n",
        "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
        "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
        "    source = map_to_base_node(rel.source)\n",
        "    target = map_to_base_node(rel.target)\n",
        "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
        "    return BaseRelationship(\n",
        "        source=source, target=target, type=rel.type, properties=properties\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmA4HorxVdwE"
      },
      "source": [
        "> Now, we will set up an extraction chain to generate a knowledge graph. A detailed prompt template that instructs the model on how to extract information. Information extracted is returned as a KnowledgeGraph class structure to ensure consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F1AJ6q_ivYGQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.chains.openai_functions import (\n",
        "    create_openai_fn_chain,\n",
        "    create_structured_output_chain,\n",
        ")\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0 )\n",
        "\n",
        "def get_extraction_chain(\n",
        "    allowed_nodes: Optional[List[str]] = None,\n",
        "    allowed_rels: Optional[List[str]] = None\n",
        "    ):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [(\n",
        "          \"system\",\n",
        "          f\"\"\"# Knowledge Graph Instructions for GPT-4\n",
        "## 1. Overview\n",
        "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
        "- **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
        "- The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
        "## 2. Labeling Nodes\n",
        "- **Consistency**: Ensure you use basic or elementary types for node labels.\n",
        "  - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
        "- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
        "{'- **Allowed Node Labels:**' + \", \".join(allowed_nodes) if allowed_nodes else \"\"}\n",
        "## 3. Labelling Relationships\n",
        "{'- **Allowed Relationship Types**:' + \", \".join(allowed_rels) if allowed_rels else \"\"}\n",
        "## 4. Handling Numerical Data and Dates\n",
        "- Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
        "- **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
        "- **Property Format**: Properties must be in a key-value format.\n",
        "- **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
        "- **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
        "## 5. Coreference Resolution\n",
        "- **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
        "If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),\n",
        "always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\n",
        "Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\n",
        "## 6. Strict Compliance\n",
        "Adhere to the rules strictly. Non-compliance will result in termination.\n",
        "          \"\"\"),\n",
        "            (\"human\", \"Use the given format to extract information from the following input: {input}\"),\n",
        "            (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
        "        ])\n",
        "    return create_structured_output_chain(KnowledgeGraph, llm, prompt, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ_IbzHXWp-N"
      },
      "source": [
        "> Now that we have identified the nodes and relationships, we are able to construct a GraphDocument with it. The function belows uploads the constructed GraphDocument onto Neo4j database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQnisioc1d9E"
      },
      "source": [
        "# Evaluation\n",
        "What's the point of having code if it doesn't work? Let's test it out.\n",
        "\n",
        "<br>\n",
        "Data would be taken from the first article that shows up on wikipedia after querying \"Johor Attack\"  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2fVOebv657Am"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='KUALA LUMPUR, Malaysia (AP) — The man who attacked a Malaysian police station and killed two officers was a recluse and is believed to have acted on his own despite suspected links to the Jemaah Islamiyah extremist group, the country’s home minister said Saturday.\\n\\nThe man stormed the police station in southern Johor state near Singapore in the early hours of Friday with a machete. He hacked a police constable to death and then used the officer’s weapon to kill another. He wounded a third officer before being shot dead. Police initially said the man could have attempted to take firearms from the station.\\n\\nHome Minister Saifuddin Nasution called it a “lone wolf attack” based on an initial investigation and said there was no threat to the wider public.\\n\\n“We have established that the attacker acted on his own ... a lone wolf driven by certain motivation and his own understanding,” Saifuddin said. “His action is not linked to any larger mission.”\\n\\nPolice have said the man’s father was a known member of Jemaah Islamiyah, a Southeast Asian network linked to al-Qaida, and that they found materials linked to the group in their home. Seven people including the man’s parents and three siblings were detained and police said they were searching for some 20 Jemaah Islamiyah members in the state.\\n'\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "def load_text_to_document(file_path: str) -> Document:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text_content = file.read()\n",
        "    \n",
        "    # Create a Document object\n",
        "    document = Document(page_content=text_content)\n",
        "    return document\n",
        "\n",
        "document = load_text_to_document(\"./test_text.txt\")\n",
        "print(document)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0nljR256Rvv",
        "outputId": "bb80db27-62c7-4bc0-9559-311f1e643999"
      },
      "outputs": [],
      "source": [
        "# ONLY USE TO DELETE THE DATABASE WHEN NEEDED FOR TESTING\n",
        "# graph.query(\"MATCH (n) DETACH DELETE n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoP5bOcA1iEg",
        "outputId": "04e672e5-f1a9-43ce-bc23-1d3ec739e986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nodes=[Node(id='Kuala Lumpur', type='Location', properties={'name': 'Kuala Lumpur'}), Node(id='Malaysia', type='Location', properties={'name': 'Malaysia'}), Node(id='Ap', type='Object', properties={'name': 'Ap'}), Node(id='Jemaah Islamiyah', type='Object', properties={'name': 'Jemaah Islamiyah'}), Node(id='Home Minister', type='Person', properties={'name': 'Home Minister'}), Node(id='Saturday', type='Event', properties={'name': 'Saturday'}), Node(id='Johor State', type='Location', properties={'name': 'Johor State'}), Node(id='Singapore', type='Location', properties={'name': 'Singapore'}), Node(id='Friday', type='Event', properties={'name': 'Friday'}), Node(id='Machete', type='Object', properties={'name': 'Machete'}), Node(id='Police Constable', type='Person', properties={'name': 'Police Constable'}), Node(id='Officer', type='Person', properties={'name': 'Officer'}), Node(id='Weapon', type='Object', properties={'name': 'Weapon'}), Node(id='Third Officer', type='Person', properties={'name': 'Third Officer'}), Node(id='Shot Dead', type='Event', properties={'name': 'Shot Dead'}), Node(id='Firearms', type='Object', properties={'name': 'Firearms'}), Node(id='Saifuddin Nasution', type='Person', properties={'name': 'Saifuddin Nasution'}), Node(id='Lone Wolf Attack', type='Event', properties={'name': 'Lone Wolf Attack'}), Node(id='Investigation', type='Event', properties={'name': 'Investigation'}), Node(id='Wider Public', type='Object', properties={'name': 'Wider Public'}), Node(id='Motivation', type='Object', properties={'name': 'Motivation'}), Node(id='Understanding', type='Object', properties={'name': 'Understanding'}), Node(id='Larger Mission', type='Event', properties={'name': 'Larger Mission'}), Node(id='Father', type='Person', properties={'name': 'Father'}), Node(id='Jemaah Islamiyah', type='Object', properties={'name': 'Jemaah Islamiyah'}), Node(id='Southeast Asian Network', type='Object', properties={'name': 'Southeast Asian Network'}), Node(id='Al-Qaida', type='Object', properties={'name': 'Al-Qaida'}), Node(id='Materials', type='Object', properties={'name': 'Materials'}), Node(id='Home', type='Location', properties={'name': 'Home'}), Node(id='Seven People', type='Person', properties={'name': 'Seven People'}), Node(id='Parents', type='Person', properties={'name': 'Parents'}), Node(id='Siblings', type='Person', properties={'name': 'Siblings'}), Node(id='Detained', type='Event', properties={'name': 'Detained'}), Node(id='Searching', type='Event', properties={'name': 'Searching'}), Node(id='Jemaah Islamiyah Members', type='Person', properties={'name': 'Jemaah Islamiyah Members'}), Node(id='State', type='Location', properties={'name': 'State'})] relationships=[Relationship(source=Node(id='Ap', type='Object', properties={'name': 'Ap'}), target=Node(id='Kuala Lumpur', type='Location', properties={'name': 'Kuala Lumpur'}), type='LOCATED_AT'), Relationship(source=Node(id='Ap', type='Object', properties={'name': 'Ap'}), target=Node(id='Malaysia', type='Location', properties={'name': 'Malaysia'}), type='LOCATED_AT'), Relationship(source=Node(id='Home Minister', type='Person', properties={'name': 'Home Minister'}), target=Node(id='Saturday', type='Event', properties={'name': 'Saturday'}), type='ORGANIZED_BY'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Johor State', type='Location', properties={'name': 'Johor State'}), type='LOCATED_AT'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Singapore', type='Location', properties={'name': 'Singapore'}), type='LOCATED_AT'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Friday', type='Event', properties={'name': 'Friday'}), type='INVOLVED_IN'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Machete', type='Object', properties={'name': 'Machete'}), type='USED_BY'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Police Constable', type='Person', properties={'name': 'Police Constable'}), type='VICTIM_OF'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Officer', type='Person', properties={'name': 'Officer'}), type='VICTIM_OF'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Weapon', type='Object', properties={'name': 'Weapon'}), type='POSSESSED_BY'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Third Officer', type='Person', properties={'name': 'Third Officer'}), type='AFFECTED_BY'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Shot Dead', type='Event', properties={'name': 'Shot Dead'}), type='INVOLVED_IN'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Firearms', type='Object', properties={'name': 'Firearms'}), type='INVOLVED_IN'), Relationship(source=Node(id='Home Minister', type='Person', properties={'name': 'Home Minister'}), target=Node(id='Lone Wolf Attack', type='Event', properties={'name': 'Lone Wolf Attack'}), type='INVOLVED_IN'), Relationship(source=Node(id='Home Minister', type='Person', properties={'name': 'Home Minister'}), target=Node(id='Investigation', type='Event', properties={'name': 'Investigation'}), type='INVOLVED_IN'), Relationship(source=Node(id='Home Minister', type='Person', properties={'name': 'Home Minister'}), target=Node(id='Wider Public', type='Object', properties={'name': 'Wider Public'}), type='AFFECTED_BY'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Motivation', type='Object', properties={'name': 'Motivation'}), type='AFFECTED_BY'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Understanding', type='Object', properties={'name': 'Understanding'}), type='AFFECTED_BY'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Larger Mission', type='Event', properties={'name': 'Larger Mission'}), type='AFFECTED_BY'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Father', type='Person', properties={'name': 'Father'}), type='POSSESSED_BY'), Relationship(source=Node(id='Father', type='Person', properties={'name': 'Father'}), target=Node(id='Jemaah Islamiyah', type='Object', properties={'name': 'Jemaah Islamiyah'}), type='INVOLVED_IN'), Relationship(source=Node(id='Father', type='Person', properties={'name': 'Father'}), target=Node(id='Southeast Asian Network', type='Object', properties={'name': 'Southeast Asian Network'}), type='INVOLVED_IN'), Relationship(source=Node(id='Southeast Asian Network', type='Object', properties={'name': 'Southeast Asian Network'}), target=Node(id='Al-Qaida', type='Object', properties={'name': 'Al-Qaida'}), type='INVOLVED_IN'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Materials', type='Object', properties={'name': 'Materials'}), type='FOUND_AT'), Relationship(source=Node(id='Home', type='Location', properties={'name': 'Home'}), target=Node(id='Materials', type='Object', properties={'name': 'Materials'}), type='LOCATED_AT'), Relationship(source=Node(id='Man', type='Person', properties={'name': 'Man'}), target=Node(id='Seven People', type='Person', properties={'name': 'Seven People'}), type='AFFECTED_BY'), Relationship(source=Node(id='Seven People', type='Person', properties={'name': 'Seven People'}), target=Node(id='Parents', type='Person', properties={'name': 'Parents'}), type='POSSESSED_BY'), Relationship(source=Node(id='Seven People', type='Person', properties={'name': 'Seven People'}), target=Node(id='Siblings', type='Person', properties={'name': 'Siblings'}), type='POSSESSED_BY'), Relationship(source=Node(id='Seven People', type='Person', properties={'name': 'Seven People'}), target=Node(id='Detained', type='Event', properties={'name': 'Detained'}), type='INVOLVED_IN'), Relationship(source=Node(id='Police', type='Person', properties={'name': 'Police'}), target=Node(id='Searching', type='Event', properties={'name': 'Searching'}), type='INVOLVED_IN'), Relationship(source=Node(id='Police', type='Person', properties={'name': 'Police'}), target=Node(id='Jemaah Islamiyah Members', type='Person', properties={'name': 'Jemaah Islamiyah Members'}), type='INVOLVED_IN'), Relationship(source=Node(id='State', type='Location', properties={'name': 'State'}), target=Node(id='Jemaah Islamiyah Members', type='Person', properties={'name': 'Jemaah Islamiyah Members'}), type='LOCATED_AT')] source=Document(page_content='KUALA LUMPUR, Malaysia (AP) — The man who attacked a Malaysian police station and killed two officers was a recluse and is believed to have acted on his own despite suspected links to the Jemaah Islamiyah extremist group, the country’s home minister said Saturday.\\n\\nThe man stormed the police station in southern Johor state near Singapore in the early hours of Friday with a machete. He hacked a police constable to death and then used the officer’s weapon to kill another. He wounded a third officer before being shot dead. Police initially said the man could have attempted to take firearms from the station.\\n\\nHome Minister Saifuddin Nasution called it a “lone wolf attack” based on an initial investigation and said there was no threat to the wider public.\\n\\n“We have established that the attacker acted on his own ... a lone wolf driven by certain motivation and his own understanding,” Saifuddin said. “His action is not linked to any larger mission.”\\n\\nPolice have said the man’s father was a known member of Jemaah Islamiyah, a Southeast Asian network linked to al-Qaida, and that they found materials linked to the group in their home. Seven people including the man’s parents and three siblings were detained and police said they were searching for some 20 Jemaah Islamiyah members in the state.\\n', metadata={'id': '43cba4689db66a60586759348e17f225'})\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "\n",
        "def extract_and_store_graph( document: str, nodes: List[str], rels: List[str] ):\n",
        "    # Extract graph data using OpenAI functions\n",
        "    extract_chain = get_extraction_chain(nodes, rels)\n",
        "    data = extract_chain.invoke(document)['function']\n",
        "    # Construct a graph document\n",
        "    graph_document = GraphDocument(nodes = [map_to_base_node(node) for node in data.nodes], relationships = [map_to_base_relationship(rel) for rel in data.rels],source = document)\n",
        "    # Store information into a graph\n",
        "    graph.add_graph_documents([graph_document])\n",
        "    return graph_document\n",
        "graph_doc = extract_and_store_graph(document=document,nodes=[\"Person\", \"Object\", \"Location\", \"Event\"], rels=[\"INVOLVED_IN\", \"ORGANIZED_BY\", \"POSSESSED_BY\", \"VICTIM_OF\", \"AFFECTED_BY\", \"USED_BY\", \"LOCATED_AT\", \"FOUND_AT\"] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Node(id='Kuala Lumpur', type='Location', properties={'name': 'Kuala Lumpur'}), Node(id='Malaysia', type='Location', properties={'name': 'Malaysia'}), Node(id='Ap', type='Object', properties={'name': 'Ap'}), Node(id='Jemaah Islamiyah', type='Object', properties={'name': 'Jemaah Islamiyah'}), Node(id='Home Minister', type='Person', properties={'name': 'Home Minister'}), Node(id='Saturday', type='Event', properties={'name': 'Saturday'}), Node(id='Johor State', type='Location', properties={'name': 'Johor State'}), Node(id='Singapore', type='Location', properties={'name': 'Singapore'}), Node(id='Friday', type='Event', properties={'name': 'Friday'}), Node(id='Machete', type='Object', properties={'name': 'Machete'}), Node(id='Police Constable', type='Person', properties={'name': 'Police Constable'}), Node(id='Officer', type='Person', properties={'name': 'Officer'}), Node(id='Weapon', type='Object', properties={'name': 'Weapon'}), Node(id='Third Officer', type='Person', properties={'name': 'Third Officer'}), Node(id='Shot Dead', type='Event', properties={'name': 'Shot Dead'}), Node(id='Firearms', type='Object', properties={'name': 'Firearms'}), Node(id='Saifuddin Nasution', type='Person', properties={'name': 'Saifuddin Nasution'}), Node(id='Lone Wolf Attack', type='Event', properties={'name': 'Lone Wolf Attack'}), Node(id='Investigation', type='Event', properties={'name': 'Investigation'}), Node(id='Wider Public', type='Object', properties={'name': 'Wider Public'}), Node(id='Motivation', type='Object', properties={'name': 'Motivation'}), Node(id='Understanding', type='Object', properties={'name': 'Understanding'}), Node(id='Larger Mission', type='Event', properties={'name': 'Larger Mission'}), Node(id='Father', type='Person', properties={'name': 'Father'}), Node(id='Jemaah Islamiyah', type='Object', properties={'name': 'Jemaah Islamiyah'}), Node(id='Southeast Asian Network', type='Object', properties={'name': 'Southeast Asian Network'}), Node(id='Al-Qaida', type='Object', properties={'name': 'Al-Qaida'}), Node(id='Materials', type='Object', properties={'name': 'Materials'}), Node(id='Home', type='Location', properties={'name': 'Home'}), Node(id='Seven People', type='Person', properties={'name': 'Seven People'}), Node(id='Parents', type='Person', properties={'name': 'Parents'}), Node(id='Siblings', type='Person', properties={'name': 'Siblings'}), Node(id='Detained', type='Event', properties={'name': 'Detained'}), Node(id='Searching', type='Event', properties={'name': 'Searching'}), Node(id='Jemaah Islamiyah Members', type='Person', properties={'name': 'Jemaah Islamiyah Members'}), Node(id='State', type='Location', properties={'name': 'State'})]\n",
            "KUALA LUMPUR, Malaysia (AP) — The man who attacked a Malaysian police station and killed two officers was a recluse and is believed to have acted on his own despite suspected links to the Jemaah Islamiyah extremist group, the country’s home minister said Saturday.\n",
            "\n",
            "The man stormed the police station in southern Johor state near Singapore in the early hours of Friday with a machete. He hacked a police constable to death and then used the officer’s weapon to kill another. He wounded a third officer before being shot dead. Police initially said the man could have attempted to take firearms from the station.\n",
            "\n",
            "Home Minister Saifuddin Nasution called it a “lone wolf attack” based on an initial investigation and said there was no threat to the wider public.\n",
            "\n",
            "“We have established that the attacker acted on his own ... a lone wolf driven by certain motivation and his own understanding,” Saifuddin said. “His action is not linked to any larger mission.”\n",
            "\n",
            "Police have said the man’s father was a known member of Jemaah Islamiyah, a Southeast Asian network linked to al-Qaida, and that they found materials linked to the group in their home. Seven people including the man’s parents and three siblings were detained and police said they were searching for some 20 Jemaah Islamiyah members in the state.\n",
            "\n",
            "['KUALA LUMPUR, Malaysia (AP) — The man who attacked a Malaysian police station and killed two officers was a recluse and is believed to have acted on his own despite suspected links to the Jemaah Islamiyah extremist group, the country’s home minister said Saturday.', '\\nThe man stormed the police station in southern Johor state near Singapore in the early hours of Friday with a machete.', 'He hacked a police constable to death and then used the officer’s weapon to kill another.', 'He wounded a third officer before being shot dead.', 'Police initially said the man could have attempted to take firearms from the station.', '\\nHome Minister Saifuddin Nasution called it a “lone wolf attack” based on an initial investigation and said there was no threat to the wider public.', '\\n“We have established that the attacker acted on his own ...', 'a lone wolf driven by certain motivation and his own understanding,” Saifuddin said.', '“His action is not linked to any larger mission.”\\n\\nPolice have said the man’s father was a known member of Jemaah Islamiyah, a Southeast Asian network linked to al-Qaida, and that they found materials linked to the group in their home.', 'Seven people including the man’s parents and three siblings were detained and police said they were searching for some 20 Jemaah Islamiyah members in the state.', '']\n",
            "[1234, 3456]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "print(graph_doc.nodes)\n",
        "print(document.page_content)\n",
        "\n",
        "def combine_with_overlap(arr, overlap):\n",
        "    combined_list = []\n",
        "    length = len(arr)\n",
        "    if length < overlap:\n",
        "        return combined_list\n",
        "    i = 0\n",
        "    while i + overlap < length:\n",
        "        combined_number = int(''.join(map(str, arr[i:i + overlap + 2])))\n",
        "        combined_list.append(combined_number)\n",
        "        i += overlap\n",
        "    \n",
        "    return combined_list\n",
        "\n",
        "sentences = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s').split(document.page_content)\n",
        "result = combine_with_overlap(sentences, 2)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0zKjjd-2Fgs"
      },
      "outputs": [],
      "source": [
        "#adhi's code\n",
        "'''\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "#no. of search results\n",
        "n = 40 #for 40 results ~15 of them are yt/twitter links so they turn out as null\n",
        "query = \"Johor attack\"\n",
        "\n",
        "\n",
        "def google_search(query, page):\n",
        "    start = page * 10\n",
        "    url = f\"https://www.google.com/search?q={query}&start={start}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "def scrape_links_and_content(query, num_pages= int(n/10)):\n",
        "    links = []\n",
        "    for page in range(num_pages):\n",
        "        soup = google_search(query, page)\n",
        "        for item in soup.find_all('div', class_='g'):\n",
        "            link_element = item.find('a', href=True)\n",
        "            if link_element:\n",
        "                link = link_element['href']\n",
        "               # datetime_of_article = get_datetime_of_article(link)\n",
        "                content = scrape_content(link)\n",
        "                links.append({\n",
        "                    \"link\": link,\n",
        "                    #\"datetime\": datetime_of_article,\n",
        "                    \"content\": content\n",
        "                })\n",
        "            if len(links) > n:\n",
        "                break\n",
        "        if len(links) > n:\n",
        "            break\n",
        "    return links\n",
        "\n",
        "#def get_datetime_of_article(link):\n",
        " #   return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "def scrape_content(link):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(link, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        paragraphs = soup.find_all('p')\n",
        "        content = ' '.join(p.get_text() for p in paragraphs)\n",
        "        return content\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching content from {link}: {e}\")\n",
        "        return None\n",
        "\n",
        "#some really rapz cleaning\n",
        "def clean_json(data):\n",
        "    cleaned_data = {}\n",
        "    for key, value in data.items():\n",
        "        if isinstance(value, str):\n",
        "            cleaned_value = value.replace('\\n', ' ').replace('\\r', '').replace('\\t', '')\n",
        "            cleaned_value = re.sub(r'[\\u0080-\\uffff]', ' ', cleaned_value)\n",
        "\n",
        "            cleaned_data[key] = cleaned_value\n",
        "        elif isinstance(value, dict):\n",
        "            cleaned_data[key] = clean_json(value)\n",
        "        elif isinstance(value, list):\n",
        "            cleaned_data[key] = [clean_json(item) for item in value]\n",
        "        else:\n",
        "            cleaned_data[key] = value\n",
        "    return cleaned_data\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    results = scrape_links_and_content(query, num_pages= int(n/10))\n",
        "    search_result = {\n",
        "        \"query\": query,\n",
        "        \"results\": results\n",
        "    }\n",
        "\n",
        "    with open('search_results.json', 'a') as f:\n",
        "        json.dump(clean_json(search_result), f, indent=4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeiWUq7NK9zD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
