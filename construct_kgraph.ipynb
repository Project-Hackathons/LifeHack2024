{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Project-Hackathons/LifeHack2024/blob/main/TerrorViz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP-YZNpqVHXj"
      },
      "source": [
        "## **Goal**\n",
        "The goal of this document is to construct a Knowledge Graph "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPkDyBARM8yr"
      },
      "source": [
        "## Dependencies\n",
        "To run this project, the following dependencies are required:\n",
        "\n",
        "*   langchain: A library to facilitate the creation of language models\n",
        "*   neo4j: A graph database management system to store and query the knowledge graph.\n",
        "*   openai: To access and use OpenAI's language models.\n",
        "*   langchain_openai: Integrates LangChain with OpenAI's models.\n",
        "*   langchain-community: Additional LangChain community tools and integrations.\n",
        "*   spacy: SpaCy is a robust Python library for advanced natural language processing tasks\n",
        "*   fastcoreref: fast, efficient library for coreference resolution that uses neural networks to identify and link references to the same entities within a text.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aHbRmW4KhiJb",
        "outputId": "1abc86b5-9bd7-47ea-af95-0c801f291d75"
      },
      "outputs": [],
      "source": [
        "%pip install langchain neo4j openai langchain_openai langchain-community setuptools wheel spacy fastcoref"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeY1BRfIptQm"
      },
      "source": [
        "## Loading environment variables \n",
        "Four key environment variables are needed for this project:\n",
        "* NEO4J_URI\n",
        "* NEO4J_USERNAME\n",
        "* NEO4J_PASSWORD\n",
        "* OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jwUzgb28mdw8"
      },
      "outputs": [],
      "source": [
        "# Import secrets and initialise Neo4jGraph\n",
        "from langchain.graphs import Neo4jGraph\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "graph = Neo4jGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maqbU8MdVEAm"
      },
      "source": [
        "## Redefining Classes and Functions\n",
        "In this section below, we will redefine some classes and functions to fit out use case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from spacy.tokens import Doc, Span\n",
        "from typing import List\n",
        "\n",
        "# functions for coreference resolution\n",
        "def get_fast_cluster_spans(doc, clusters):\n",
        "    fast_clusters = []\n",
        "    for cluster in clusters:\n",
        "        new_group = []\n",
        "        for tuple in cluster:\n",
        "            (start, end) = tuple\n",
        "            span = doc.char_span(start, end)\n",
        "            new_group.append([span.start, span.end-1])\n",
        "        fast_clusters.append(new_group)\n",
        "    return fast_clusters\n",
        "\n",
        "def get_fastcoref_clusters(doc, text):\n",
        "    preds = model.predict(texts=[text])\n",
        "    fast_clusters = preds[0].get_clusters(as_strings=False)\n",
        "    fast_cluster_spans = get_fast_cluster_spans(doc, fast_clusters)\n",
        "    return fast_cluster_spans\n",
        "\n",
        "\n",
        "def core_logic_part(document: Doc, coref: List[int], resolved: List[str], mention_span: Span):\n",
        "    final_token = document[coref[1]]\n",
        "    if final_token.tag_ in [\"PRP$\", \"POS\"]:\n",
        "        resolved[coref[0]] = mention_span.text + \"'s\" + final_token.whitespace_\n",
        "    else:\n",
        "        resolved[coref[0]] = mention_span.text + final_token.whitespace_\n",
        "    for i in range(coref[0] + 1, coref[1] + 1):\n",
        "        resolved[i] = \"\"\n",
        "    return resolved\n",
        "\n",
        "def get_span_noun_indices(doc: Doc, cluster: List[List[int]]) -> List[int]:\n",
        "    spans = [doc[span[0]:span[1]+1] for span in cluster]\n",
        "    spans_pos = [[token.pos_ for token in span] for span in spans]\n",
        "    span_noun_indices = [i for i, span_pos in enumerate(spans_pos)\n",
        "        if any(pos in span_pos for pos in ['NOUN', 'PROPN'])]\n",
        "    return span_noun_indices\n",
        "\n",
        "def get_cluster_head(doc: Doc, cluster: List[List[int]], noun_indices: List[int]):\n",
        "    head_idx = noun_indices[0]\n",
        "    head_start, head_end = cluster[head_idx]\n",
        "    head_span = doc[head_start:head_end+1]\n",
        "    return head_span, [head_start, head_end]\n",
        "\n",
        "def is_containing_other_spans(span: List[int], all_spans: List[List[int]]):\n",
        "    return any([s[0] >= span[0] and s[1] <= span[1] and s != span for s in all_spans])\n",
        "\n",
        "def improved_replace_corefs(document, clusters):\n",
        "    resolved = list(tok.text_with_ws for tok in document)\n",
        "    all_spans = [span for cluster in clusters for span in cluster] \n",
        "\n",
        "    for cluster in clusters:\n",
        "        noun_indices = get_span_noun_indices(document, cluster)\n",
        "\n",
        "        if noun_indices:\n",
        "            mention_span, mention = get_cluster_head(document, cluster, noun_indices)\n",
        "\n",
        "            for coref in cluster:\n",
        "                if coref != mention and not is_containing_other_spans(coref, all_spans):\n",
        "                    core_logic_part(document, coref, resolved, mention_span)\n",
        "\n",
        "    return \"\".join(resolved)\n",
        "\n",
        "def load_text_to_document(file_path: str) -> Document:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text_content = file.read()\n",
        "    print(f'Before Coreference Resolution:\\n{text_content}')\n",
        "    doc = nlp(text_content) \n",
        "    clusters = get_fastcoref_clusters(doc, text_content) \n",
        "    coref_text = improved_replace_corefs(doc, clusters) \n",
        "\n",
        "    document = Document(page_content=coref_text)\n",
        "    return document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aCQQjZnftvgB"
      },
      "outputs": [],
      "source": [
        "# Redefining classes to overight existing pydantic classes. \n",
        "# Final KnowledgeGraph class will be passed to LLM so that it knows the output format. \n",
        "# This is to help LLM identify Nodes and Relationships.\n",
        "\n",
        "from langchain_community.graphs.graph_document import (\n",
        "    Node as BaseNode,\n",
        "    Relationship as BaseRelationship,\n",
        "    GraphDocument,\n",
        ")\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain.pydantic_v1 import Field, BaseModel\n",
        "\n",
        "class Property(BaseModel):\n",
        "  \"\"\"A single property consisting of key and value\"\"\"\n",
        "  key: str = Field(..., description=\"key\")\n",
        "  value: str = Field(..., description=\"value\")\n",
        "\n",
        "class Node(BaseNode):\n",
        "    properties: Optional[List[Property]] = Field(\n",
        "        None, description=\"List of node properties\")\n",
        "\n",
        "class Relationship(BaseRelationship):\n",
        "    properties: Optional[List[Property]] = Field(\n",
        "        None, description=\"List of relationship properties\"\n",
        "    )\n",
        "\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
        "    nodes: List[Node] = Field(\n",
        "        ..., description=\"List of nodes in the knowledge graph\")\n",
        "    rels: List[Relationship] = Field(\n",
        "        ..., description=\"List of relationships in the knowledge graph\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F1AJ6q_ivYGQ"
      },
      "outputs": [],
      "source": [
        "# Function that instructs LLM to identify Nodes and Relationship and output the result in the desired format (KnowledgeGraph Class)\n",
        "# Note that even though we are prompting LLM to do coreference resolution, it will be done before the document is passed into the LLM using spacy. \n",
        "# This additional coreference resolution is just an additional safety net.\n",
        "\n",
        "from langchain.chains.openai_functions import (create_structured_output_chain,)\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0 )\n",
        "\n",
        "def get_extraction_chain(\n",
        "    allowed_nodes: Optional[List[str]] = None,\n",
        "    allowed_rels: Optional[List[str]] = None\n",
        "    ):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [(\n",
        "          \"system\",\n",
        "          f\"\"\"# Knowledge Graph Instructions for GPT-4\n",
        "## 1. Overview\n",
        "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
        "- **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
        "- The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
        "## 2. Labeling Nodes\n",
        "- **Consistency**: Ensure you use basic or elementary types for node labels.\n",
        "  - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
        "- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
        "{'- **Allowed Node Labels:**' + \", \".join(allowed_nodes) if allowed_nodes else \"\"}\n",
        "## 3. Labelling Relationships\n",
        "{'- **Allowed Relationship Types**:' + \", \".join(allowed_rels) if allowed_rels else \"\"}\n",
        "## 4. Handling Numerical Data and Dates\n",
        "- Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
        "- **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
        "- **Property Format**: Properties must be in a key-value format.\n",
        "- **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
        "- **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
        "## 5. Coreference Resolution\n",
        "- **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
        "If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),\n",
        "always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\n",
        "Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\n",
        "## 6. Strict Compliance\n",
        "Adhere to the rules strictly. Non-compliance will result in termination.\n",
        "          \"\"\"),\n",
        "            (\"human\", \"Use the given format to extract information from the following input: {input}\"),\n",
        "            (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
        "        ])\n",
        "    return create_structured_output_chain(KnowledgeGraph, llm, prompt, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "63OZD7fkukHM"
      },
      "outputs": [],
      "source": [
        "# Functions to reformat ouput by LLM before passing information over to Neo4j\n",
        "def format_property_key(s: str) -> str:\n",
        "    words = s.split()\n",
        "    if not words:\n",
        "        return s\n",
        "    first_word = words[0].lower()\n",
        "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
        "    return \"\".join([first_word] + capitalized_words)\n",
        "\n",
        "def props_to_dict(props) -> dict:\n",
        "    \"\"\"Convert properties to a dictionary.\"\"\"\n",
        "    properties = {}\n",
        "    if not props:\n",
        "      return properties\n",
        "    for p in props:\n",
        "        properties[format_property_key(p.key)] = p.value\n",
        "    return properties\n",
        "\n",
        "def map_to_base_node(node: Node) -> BaseNode:\n",
        "    \"\"\"Map the KnowledgeGraph Node to the base Node.\"\"\"\n",
        "    properties = props_to_dict(node.properties) if node.properties else {}\n",
        "    # Add name property for better Cypher statement generation\n",
        "    properties[\"name\"] = node.id.title()\n",
        "    return BaseNode(\n",
        "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
        "    )\n",
        "\n",
        "\n",
        "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
        "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
        "    source = map_to_base_node(rel.source)\n",
        "    target = map_to_base_node(rel.target)\n",
        "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
        "    return BaseRelationship(\n",
        "        source=source, target=target, type=rel.type, properties=properties\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQnisioc1d9E"
      },
      "source": [
        "## Evaluation\n",
        "Let's test out the functions we have implemented so far!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ernesttan/miniconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "06/01/2024 10:54:20 - INFO - \t missing_keys: []\n",
            "06/01/2024 10:54:20 - INFO - \t unexpected_keys: []\n",
            "06/01/2024 10:54:20 - INFO - \t mismatched_keys: []\n",
            "06/01/2024 10:54:20 - INFO - \t error_msgs: []\n",
            "06/01/2024 10:54:20 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n"
          ]
        }
      ],
      "source": [
        "# instantiate nlp and model objects for coreference resolution\n",
        "import spacy\n",
        "from fastcoref import FCoref\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "model = FCoref()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2fVOebv657Am"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "06/01/2024 10:54:20 - INFO - \t Tokenize 1 inputs...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Coreference Resolution:\n",
            "KUALA LUMPUR, Malaysia (AP) — The man who attacked a Malaysian police station and killed two officers was a recluse and is believed to have acted on his own despite suspected links to the Jemaah Islamiyah extremist group, the country’s home minister said Saturday.\n",
            "\n",
            "The man stormed the police station in southern Johor state near Singapore in the early hours of Friday with a machete. He hacked a police constable to death and then used the officer’s weapon to kill another. He wounded a third officer before being shot dead. Police initially said the man could have attempted to take firearms from the station.\n",
            "\n",
            "Home Minister Saifuddin Nasution called it a “lone wolf attack” based on an initial investigation and said there was no threat to the wider public.\n",
            "\n",
            "“We have established that the attacker acted on his own ... a lone wolf driven by certain motivation and his own understanding,” Saifuddin said. “His action is not linked to any larger mission.”\n",
            "\n",
            "Police have said the man’s father was a known member of Jemaah Islamiyah, a Southeast Asian network linked to al-Qaida, and that they found materials linked to the group in their home. Seven people including the man’s parents and three siblings were detained and police said they were searching for some 20 Jemaah Islamiyah members in the state.\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f596cc1ea1984f82b525f1f7ff5d8383",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "06/01/2024 10:54:20 - INFO - \t ***** Running Inference on 1 texts *****\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3b97d464f8d42a5a7d3bf04dcd7db9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After Coreference Resolution:\n",
            "KUALA LUMPUR, Malaysia (AP) — The man who attacked a Malaysian police station and killed two officers was a recluse and is believed to have His action on The man who attacked a Malaysian police station and killed two officers's own despite suspected links to the Jemaah Islamiyah extremist group, Malaysia's home minister said Saturday.\n",
            "\n",
            "The man who attacked a Malaysian police station and killed two officers stormed the police station in southern Johor state near Singapore in the early hours of Friday with a machete. The man who attacked a Malaysian police station and killed two officers hacked a police constable to death and then used a police constable's weapon to kill another. The man who attacked a Malaysian police station and killed two officers wounded a third officer before being shot dead. Police initially said The man who attacked a Malaysian police station and killed two officers could have attempted to take firearms from a Malaysian police station.\n",
            "\n",
            "Home Minister Saifuddin Nasution called it a “lone wolf attack” based on an initial investigation and said there was no threat to the wider public.\n",
            "\n",
            "“We have established that The man who attacked a Malaysian police station and killed two officers acted on The man who attacked a Malaysian police station and killed two officers's own ... a lone wolf driven by certain motivation and The man who attacked a Malaysian police station and killed two officers's own understanding,” the country’s home minister said. “The man who attacked a Malaysian police station and killed two officers's action is not linked to any larger mission.”\n",
            "\n",
            "Police have said The man who attacked a Malaysian police station and killed two officers's father was a known member of the Jemaah Islamiyah extremist group, and that they found materials linked to the Jemaah Islamiyah extremist group in their home. Seven people including The man who attacked a Malaysian police station and killed two officers's parents and three siblings were detained and police said police were searching for some 20 the Jemaah Islamiyah extremist group members in southern Johor state near Singapore.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#coreference resolution\n",
        "document = load_text_to_document(\"./assets/test_text.txt\")\n",
        "print(f'After Coreference Resolution:\\n{document.page_content}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All pronouns have been replaced with an Entity. Coreference resolution has been successfully carried out! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0nljR256Rvv",
        "outputId": "bb80db27-62c7-4bc0-9559-311f1e643999"
      },
      "outputs": [],
      "source": [
        "# ONLY USE TO DELETE THE DATABASE WHEN NEEDED FOR TESTING\n",
        "# graph.query(\"MATCH (n) DETACH DELETE n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoP5bOcA1iEg",
        "outputId": "04e672e5-f1a9-43ce-bc23-1d3ec739e986"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ernesttan/miniconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `create_structured_output_chain` was deprecated in LangChain 0.1.1 and will be removed in 0.3.0. Use ChatOpenAI.with_structured_output instead.\n",
            "  warn_deprecated(\n",
            "06/01/2024 10:54:53 - INFO - \t HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "# After coreference resolution is completed, we now invoke a function for LLM to identify Nodes and Relationships\n",
        "# Nodes and Relationships are then reformatted before being passed to Neo4j to be populated\n",
        "from typing import List\n",
        "\n",
        "def extract_and_store_graph( document: str, nodes: List[str], rels: List[str] ):\n",
        "    # Extract graph data using OpenAI functions\n",
        "    extract_chain = get_extraction_chain(nodes, rels)\n",
        "    data = extract_chain.invoke(document)['function']\n",
        "    # Construct a graph document\n",
        "    graph_document = GraphDocument(nodes = [map_to_base_node(node) for node in data.nodes], relationships = [map_to_base_relationship(rel) for rel in data.rels],source = document)\n",
        "    # Store information into a graph\n",
        "    graph.add_graph_documents([graph_document])\n",
        "    return graph_document\n",
        "\n",
        "graph_doc = extract_and_store_graph(document=document,\n",
        "                                    nodes=[\"Person\", \"Object\", \"Location\", \"Event\"], \n",
        "                                    rels=[\"INVOLVED_IN\", \"ORGANIZED_BY\", \"POSSESSED_BY\", \"VICTIM_OF\", \"AFFECTED_BY\", \"USED_BY\", \"LOCATED_AT\", \"FOUND_AT\"] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hooray! The Knowledge Graph has been successfully populated. You can expect the knowledge graph to look like this: \n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"./assets/knowledge_graph.png\" alt=\"Knowledge Graph\" width=\"500\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's identify the entities in the extract and link the nodes back to the extract. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to identify if an entity is mentioned in a extract\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0 )\n",
        "\n",
        "def get_mentions_chain(\n",
        "    node_ids: Optional[List[str]] = None\n",
        "    ):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [(\n",
        "          \"system\",\n",
        "          f\"\"\"# Knowledge Graph Instructions for GPT-4\n",
        "## 1. Overview\n",
        "You are a top-tier algorithm to find out which entities are mentioned in an extract.\n",
        "## 2. {'- **Entities:**' + \", \".join(node_ids) if node_ids else \"\"}\n",
        "## 3. You need to output in a JSON format. It should be a list containing the entities mentioned.\n",
        "## 4. Strict Compliance\n",
        "Adhere to the rules strictly. Non-compliance will result in termination.\n",
        "          \"\"\"),\n",
        "            (\"human\", \"Use the given format to extract information from the following input: {input}\"),\n",
        "            (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
        "        ])\n",
        "    return create_structured_output_chain(List[str], llm, prompt, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "node_ids = [node.id for node in graph_doc.nodes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ernesttan/miniconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n",
            "06/01/2024 10:54:55 - INFO - \t HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:54:56 - INFO - \t HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:54:57 - INFO - \t HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:54:58 - INFO - \t HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:55:00 - INFO - \t HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:55:00 - INFO - \t HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:55:03 - INFO - \t HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:55:03 - INFO - \t HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:55:05 - INFO - \t HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "06/01/2024 10:55:06 - INFO - \t HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "# chunk the extracts \n",
        "# create vector embedding\n",
        "# map the existing nodes to the extracts\n",
        "import re\n",
        "\n",
        "def combine_with_overlap(arr, overlap):\n",
        "    combined_list = []\n",
        "    length = len(arr)\n",
        "    if length < overlap:\n",
        "        return combined_list\n",
        "    i = 0\n",
        "    while i + overlap < length:\n",
        "        combined_string = ''.join(arr[i:i + overlap + 2])\n",
        "        combined_list.append(combined_string)\n",
        "        i += overlap\n",
        "    \n",
        "    return combined_list\n",
        "\n",
        "sentences = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s').split(document.page_content)\n",
        "overlapping_extracts = combine_with_overlap(sentences, 2)\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "embedding_dimension = 1536\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "for extract in overlapping_extracts:\n",
        "    def extract_entities( document: str, node_ids: List[str] ):\n",
        "        # Extract graph data using OpenAI functions\n",
        "        extract_chain = get_mentions_chain(node_ids)\n",
        "        data = extract_chain.invoke(document)['function']\n",
        "        extract_id = str(hash(extract))\n",
        "        params = {\n",
        "            \"extract_text\": extract,\n",
        "            \"embedding\": embeddings.embed_query(extract),\n",
        "            \"extract_id\": extract_id\n",
        "        }\n",
        "\n",
        "        graph.query(\n",
        "            \"\"\"\n",
        "            MERGE (n:Extract {extract_text: $extract_text, embedding: $embedding, id: $extract_id})\n",
        "            WITH n\n",
        "            CALL db.create.setVectorProperty(n, 'extract_embedding', $embedding)\n",
        "            YIELD node\n",
        "            RETURN count(*)\n",
        "            \"\"\",\n",
        "            params,\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            graph.query(\n",
        "                \"CALL db.index.vector.createNodeIndex('extract', \"\n",
        "                \"'Extract', 'embedding', $dimension, 'cosine')\",\n",
        "                {\"dimension\": embedding_dimension},\n",
        "            )\n",
        "        except:  # already exists\n",
        "            pass\n",
        "        \n",
        "        for id in node_ids:\n",
        "            graph.query(\n",
        "                \"\"\"\n",
        "                MATCH (p {id: $id})\n",
        "                MATCH (n:Extract {id: $extract_id})\n",
        "                MERGE (n)<-[:MENTIONED_IN]-(p)\n",
        "                RETURN count(*)\n",
        "                \"\"\",\n",
        "                {\"id\": id, \"extract_id\": extract_id},\n",
        "                )\n",
        "\n",
        "        # # Construct a graph document\n",
        "        # graph_document = GraphDocument(nodes = [map_to_base_node(node) for node in data.nodes], relationships = [map_to_base_relationship(rel) for rel in data.rels],source = document)\n",
        "        # # Store information into a graph\n",
        "        # graph.add_graph_documents([graph_document])\n",
        "        # return graph_document\n",
        "    graph_doc = extract_entities(document=Document(page_content=extract), node_ids=node_ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Awesome! You have successfully linked the nodes to the extract. Your Knowledge Graph should now look like this: \n",
        "<p align=\"center\">\n",
        "<img src=\"./assets/knowledge_graph_wextracts.png\" alt=\"Knowledge Graph With Extract\" width=\"500\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### move on to [retrival.ipynb](https://github.com/Project-Hackathons/LifeHack2024/blob/main/retrival.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
